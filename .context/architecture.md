# RÃ©sumÃ© du projet

Ce dossier .context/ contient la documentation pour l'assistance IA.

Le but de ce projet est de faire une pipeline python qui permet de comparer diffÃ©rents algorithmes dâ€™apprentissage de structure dans des rÃ©seaux bayÃ©siens continus. La pipeline prend au moins un dataset en entrÃ©e (et plus tard aussi un golden BN de rÃ©fÃ©rence), exÃ©cute tous les algorithmes et comparer leurs rÃ©sultats. Ce nâ€™est quâ€™un travail dâ€™orchestration. La difficultÃ© est que les algorithmes sont implÃ©mentÃ©s dans des dÃ©pots diffÃ©rents et quâ€™il faut tout standardiser. Aussi il faut que le code puisse accepter lâ€™ajout dâ€™un nouvel algorithme Ã©crit dans un autre langage.

Dans un premier temps les algorithmes Ã  comparer sont les suivants :

- CMIIC
- CPC
- CMIIC2
- CPC2
- NOTEARS
- Lingam
- DiscrÃ©tisation + MIIC
- DiscrÃ©tisation + GHC avec score BDeu

Remarque : Ã©tant donnÃ© que CPC2 et CMIIC2 sont prÃ©sentes uniquement dans la branche cpc2_cmiic2 de mon fork https://github.com/mathisemb/otagrum/tree/cpc2_cmiic2 dâ€™otagrum, et que CPC et CMIIC sont Ã©galement prÃ©sents dedans, il peut Ãªtre utile de seulement importer cette branche de mon fork et non la vraie librairie otagrum. Peut Ãªtre que câ€™est possible avec pip install git+url_depot.

Ensuite les rÃ©sultas sont rÃ©sumÃ©s dans des heatmaps. Une heatmap par mÃ©trique. Les mÃ©triques utilisÃ©es seront dans un premier temps :

- F1-Score
- Structural Hamming Distance
- True Positive Rate

# DÃ©coupage de l'exÃ©cution

1. GÃ©nÃ©ration de donnÃ©es synthÃ©tique Ã  partir d'un CBN connu (optionnel)
2. ExÃ©cution des algorithmes sur le dataset
3. Calcul des mÃ©triques
4. PrÃ©sentation des rÃ©sultats (heatmaps, exports)

# Principes et choix de dÃ©veloppement

Le code doit Ãªtre maintenable et Ã©volutif en respectant les conventions Python.

**Contraintes** :
- Les algorithmes et mÃ©triques proviennent de dÃ©pÃ´ts diffÃ©rents â†’ couche *adapter* pour les encapsuler sans les modifier
- La pipeline ne connaÃ®t pas les algos/mÃ©triques concrÃ¨tes â†’ orchestration pure, couplage minimal
- Ajout dynamique â†’ crÃ©er un nouveau fichier suffit, sans modifier le reste
- Golden BN optionnel â†’ fonctionne avec donnÃ©es simulÃ©es ou rÃ©elles
- Gestion centralisÃ©e des types de donnÃ©es â†’ adaptations automatiques (discrÃ©tisation si nÃ©cessaire)
- Ã‰valuation et visualisation sÃ©parÃ©es â†’ modifications possibles sans toucher la pipeline
- Architecture extensible â†’ rapide Ã  implÃ©menter, compatible avec futures extensions

---

# Les objectifs

- lire tous les dÃ©pots, comprendre et faire un rÃ©sumÃ© des inputs/ouputs de chaque algorithme.
- Ã  partir de lâ€™info des inputs/outputs des algorithmes, faire la meilleure classe adapter possible.
- idem pour les mÃ©triques.
- proposer des classes pour gÃ©rer les algos et les mÃ©triques en justifiant les choix.
- proposer une structure de fichiers en justifiant les choix.
- coder une premiÃ¨re version de celles ci.
- tÃ©lÃ©charger, regarder et comprendre le dataset https://pubmed.ncbi.nlm.nih.gov/15845847/.
- Ã  partir des informations de ce dataset, Ã©crire une classe Dataset qui pourra adapter nâ€™importe quel dataset pour quâ€™il soit utilisÃ© par la pipeline.
- coder un premier exemple avec CPC, F1-Score et le dataset https://pubmed.ncbi.nlm.nih.gov/15845847/.
- continuer avec les autres algos.

---

# Ã‰tat actuel de l'implÃ©mentation

## Composants implÃ©mentÃ©s

### Pipeline principal (âœ… Fait)
- **Pipeline.py** : Orchestration principale avec la classe `StructureLearningPipeline`
- **Dataset.py** : Wrapper de donnÃ©es avec gestion des types (continu/discret)
- **Result.py** : Stockage des rÃ©sultats avec dictionnaire de mÃ©triques
- **Structure.py** : ReprÃ©sentation du CPDAG avec `gum.EssentialGraph`

### Algorithmes (ğŸ”„ En cours)
- **AlgorithmAdapter.py** : Classe abstraite de base pour tous les algorithmes
- **CPCAdapter.py** : Algorithme CPC continu depuis otagrum (âœ… implÃ©mentÃ©)
- Autres : TODO (CMIIC, CPC2, CMIIC2, NOTEARS, LiNGAM, discrÃ©tisation + MIIC/GHC)

### MÃ©triques (ğŸ”„ En cours)
- **MetricAdapter.py** : Classe abstraite de base pour toutes les mÃ©triques
- **SHDMetric.py** : Structural Hamming Distance (âœ… implÃ©mentÃ©)
- Autres : TODO (F1-Score, TPR)

### Autres modules
- **discretization/** : TODO (stratÃ©gies de conversion continuâ†’discret)
- **visualization/** : TODO (heatmaps et visualisation des rÃ©sultats)

### Tests & Exemples
- **tests/integration/test_cpc_shd.py** : Test d'intÃ©gration basique avec CPC + SHD
- **examples/basic_usage.py** : Exemple d'utilisation complet avec donnÃ©es synthÃ©tiques

## Structure actuelle du projet

```
cbnsl_benchmark/
â”œâ”€â”€ pipeline/              # Core pipeline components
â”‚   â”œâ”€â”€ Pipeline.py        # Main orchestration
â”‚   â”œâ”€â”€ Dataset.py         # Dataset wrapper
â”‚   â”œâ”€â”€ Result.py          # Result storage
â”‚   â””â”€â”€ Structure.py       # Structure representation (CPDAG)
â”‚
â”œâ”€â”€ algorithms/            # Algorithm adapters
â”‚   â”œâ”€â”€ AlgorithmAdapter.py    # Base adapter interface
â”‚   â””â”€â”€ adapters/
â”‚       â””â”€â”€ CPCAdapter.py      # CPC algorithm (âœ…)
â”‚
â”œâ”€â”€ metrics/              # Evaluation metrics
â”‚   â”œâ”€â”€ MetricAdapter.py      # Base metric interface
â”‚   â””â”€â”€ SHDMetric.py         # Structural Hamming Distance (âœ…)
â”‚
â”œâ”€â”€ discretization/       # Discretization strategies (TODO)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ visualization/        # Visualization tools (TODO)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/               # Tests
â”‚   â”œâ”€â”€ unit/            # Unit tests (TODO)
â”‚   â”œâ”€â”€ integration/     # Integration tests
â”‚   â”‚   â””â”€â”€ test_cpc_shd.py
â”‚   â””â”€â”€ fixtures/        # Test data (TODO)
â”‚
â”œâ”€â”€ examples/            # Usage examples
â”‚   â””â”€â”€ basic_usage.py
â”‚
â”œâ”€â”€ data/                # Datasets
â”‚   â””â”€â”€ synthetic/       # Synthetic datasets
â”‚
â”œâ”€â”€ results/             # Benchmark outputs (gitignored)
â”‚
â”œâ”€â”€ .context/            # Contexte IA (pas dans le package)
â”‚   â”œâ”€â”€ architecture.md  # Ce fichier
â”‚   â””â”€â”€ useful_links.md  # Liens vers code/docs externes
â”‚
â”œâ”€â”€ install.sh           # Script d'installation automatique
â”œâ”€â”€ pyproject.toml       # Configuration du package
â”œâ”€â”€ requirements.txt     # DÃ©pendances de base
â””â”€â”€ requirements-git.txt # DÃ©pendances Git
```

## DÃ©cisions architecturales (Ã©tat actuel)

### Organisation du projet

**tests/ (pluriel, pas test/)** : Suit la convention Python. SubdivisÃ© en unit/, integration/ et fixtures/ pour une meilleure organisation.

**SÃ©paration examples/ et tests/** : Distinction claire entre exemples d'utilisation et tests. Les exemples montrent comment utiliser la lib, les tests vÃ©rifient la correction.

**data/ pour datasets, results/ pour outputs** : Garde le code propre. Les deux sont gitignorÃ©s (sauf structure) pour Ã©viter de versionner de gros fichiers.

**Dataset dans pipeline/ (pas dans data/)** : `Dataset` est une abstraction avec logique (wrapper + mÃ©tadonnÃ©es), pas des donnÃ©es brutes. Appartient aux autres abstractions core comme `Result` et `Structure`.

**.context/ pour contexte IA** : Contient documentation architecture et liens externes. Pas partie du package, seulement pour dev/assistance IA.

### SystÃ¨me de types & ReprÃ©sentations

**Structure.cpdag typÃ© comme `gum.EssentialGraph`** :
- PyAgrum utilise `EssentialGraph` comme reprÃ©sentation interne d'un CPDAG
- On garde le nom conceptuel "cpdag" (Ã§a reprÃ©sente un CPDAG) mais avec des type hints honnÃªtes
- La mÃ©thode `.pdag()` convertit vers reprÃ©sentation PDAG pour l'affichage

**Pourquoi pas MixedGraph ?** : Initialement typÃ© comme `MixedGraph`, mais c'Ã©tait incorrect. `EssentialGraph` est plus spÃ©cifique et prÃ©cis.

### Design Patterns

**Pattern Adapter pour Algorithmes** : DÃ©couple les implÃ©mentations externes de notre pipeline. Chaque algo (CPC, NOTEARS, LiNGAM) a son adapter implÃ©mentant l'interface `AlgorithmAdapter`.

**Pattern Adapter pour MÃ©triques** : Similaire aux algos, permet d'ajouter nouvelles mÃ©triques sans modifier la pipeline.

**Pattern Strategy pour DiscrÃ©tisation** : PrÃ©vu pour gÃ©rer diffÃ©rentes stratÃ©gies de discrÃ©tisation (uniforme, quantile, etc.) sans hard-coder dans les adapters d'algos.

**Injection de DÃ©pendances** : Pipeline ne crÃ©e pas les algos ou mÃ©triques, ils sont injectÃ©s via `add_algorithm()` et `add_metric()`. Augmente flexibilitÃ© et testabilitÃ©.

### Gestion des types de donnÃ©es

**Adaptation automatique du Dataset** : Pipeline vÃ©rifie si le type de donnÃ©es requis par l'algo correspond au type du dataset. Sinon, applique stratÃ©gie de discrÃ©tisation automatiquement.

**Enum DataType** : Enum simple (CONTINUOUS/DISCRETE) centralise la gestion des types et Ã©vite les vÃ©rifications basÃ©es sur strings.

### Installation & DÃ©pendances

**pyproject.toml pour config package** : Standard moderne Python (PEP 621). DÃ©finit dÃ©pendances et mÃ©tadonnÃ©es du package.

**requirements-git.txt sÃ©parÃ©** : Certaines dÃ©pendances (otagrum avec CPC2/CMIIC2, notears) viennent de dÃ©pÃ´ts Git, pas PyPI.

**Script install.sh automatisÃ©** : Installation interactive gÃ©rant conda vs build cmake pour otagrum, NO TEARS optionnel, etc.

## ProblÃ¨mes connus / TODO

### Bugs Ã  corriger
- âš ï¸ **MÃ©triques non calculÃ©es dans Pipeline.run()** : Les mÃ©triques sont ajoutÃ©es au pipeline mais jamais calculÃ©es. Besoin d'appeler `metric.compute()` dans la boucle run.
- âš ï¸ **Pas de logging** : Utilise actuellement des `print()`. Devrait utiliser le module `logging` Python pour niveaux de log et configuration appropriÃ©s.

### FonctionnalitÃ©s Ã  implÃ©menter
- [ ] Algorithmes restants : CMIIC, CPC2, CMIIC2, NOTEARS, LiNGAM
- [ ] MÃ©triques restantes : F1-Score, TPR
- [ ] StratÃ©gies de discrÃ©tisation et intÃ©gration
- [ ] Module de visualisation (heatmaps)
- [ ] Tests unitaires pour tous les composants
- [ ] IntÃ©gration dataset rÃ©el (Sachs protein dataset)
- [ ] Comparaison avec structure golden et benchmarking
- [ ] Export des rÃ©sultats (CSV, JSON)
- [ ] Mesure du temps d'exÃ©cution
- [ ] ExÃ©cution parallÃ¨le des algorithmes

### AmÃ©liorations architecturales
- [ ] Ajouter logging structurÃ© partout
- [ ] AmÃ©lioration gestion d'erreurs (actuellement try/except basique)
- [ ] ComplÃ©tion des type hints (manquent Ã  certains endroits)
- [ ] GÃ©nÃ©ration documentation (Sphinx)
- [ ] Pipeline CI/CD (GitHub Actions)

## Conventions de code
- Code et commentaires en anglais
- Type hints systÃ©matiques
- Docstrings au format Google
- Pas d'emojis sauf demande explicite
