# RÃ©sumÃ© du projet

Ce dossier .context/ contient la documentation pour l'assistance IA.

Le but de ce projet est de faire une pipeline python qui permet de comparer diffÃ©rents algorithmes dâ€™apprentissage de structure dans des rÃ©seaux bayÃ©siens continus. La pipeline prend au moins un dataset en entrÃ©e (et plus tard aussi un golden BN de rÃ©fÃ©rence), exÃ©cute tous les algorithmes et comparer leurs rÃ©sultats. Ce nâ€™est quâ€™un travail dâ€™orchestration. La difficultÃ© est que les algorithmes sont implÃ©mentÃ©s dans des dÃ©pots diffÃ©rents et quâ€™il faut tout standardiser. Aussi il faut que le code puisse accepter lâ€™ajout dâ€™un nouvel algorithme Ã©crit dans un autre langage.

Dans un premier temps les algorithmes Ã  comparer sont les suivants :

- CMIIC
- CPC
- CMIIC2
- CPC2
- NOTEARS
- Lingam
- DiscrÃ©tisation + MIIC
- DiscrÃ©tisation + GHC avec score BDeu

Remarque : Ã©tant donnÃ© que CPC2 et CMIIC2 sont prÃ©sentes uniquement dans la branche cpc2_cmiic2 de mon fork https://github.com/mathisemb/otagrum/tree/cpc2_cmiic2 dâ€™otagrum, et que CPC et CMIIC sont Ã©galement prÃ©sents dedans, il peut Ãªtre utile de seulement importer cette branche de mon fork et non la vraie librairie otagrum. Peut Ãªtre que câ€™est possible avec pip install git+url_depot.

Ensuite les rÃ©sultas sont rÃ©sumÃ©s dans des heatmaps. Une heatmap par mÃ©trique. Les mÃ©triques utilisÃ©es seront dans un premier temps :

- F1-Score
- Structural Hamming Distance
- True Positive Rate

# DÃ©coupage de l'exÃ©cution

1. GÃ©nÃ©ration de donnÃ©es synthÃ©tique Ã  partir d'un CBN connu (optionnel)
2. ExÃ©cution des algorithmes sur le dataset
3. Calcul des mÃ©triques
4. PrÃ©sentation des rÃ©sultats (heatmaps, exports)

# Principes et choix de dÃ©veloppement

Le code doit Ãªtre maintenable et Ã©volutif en respectant les conventions Python.

**Contraintes** :
- Les algorithmes et mÃ©triques proviennent de dÃ©pÃ´ts diffÃ©rents â†’ couche *adapter* pour les encapsuler sans les modifier
- La pipeline ne connaÃ®t pas les algos/mÃ©triques concrÃ¨tes â†’ orchestration pure, couplage minimal
- Ajout dynamique â†’ crÃ©er un nouveau fichier suffit, sans modifier le reste
- Golden BN optionnel â†’ fonctionne avec donnÃ©es simulÃ©es ou rÃ©elles
- Gestion centralisÃ©e des types de donnÃ©es â†’ adaptations automatiques (discrÃ©tisation si nÃ©cessaire)
- Ã‰valuation et visualisation sÃ©parÃ©es â†’ modifications possibles sans toucher la pipeline
- Architecture extensible â†’ rapide Ã  implÃ©menter, compatible avec futures extensions

---

# Les objectifs

- lire tous les dÃ©pots, comprendre et faire un rÃ©sumÃ© des inputs/ouputs de chaque algorithme.
- Ã  partir de lâ€™info des inputs/outputs des algorithmes, faire la meilleure classe adapter possible.
- idem pour les mÃ©triques.
- proposer des classes pour gÃ©rer les algos et les mÃ©triques en justifiant les choix.
- proposer une structure de fichiers en justifiant les choix.
- coder une premiÃ¨re version de celles ci.
- tÃ©lÃ©charger, regarder et comprendre le dataset https://pubmed.ncbi.nlm.nih.gov/15845847/.
- Ã  partir des informations de ce dataset, Ã©crire une classe Dataset qui pourra adapter nâ€™importe quel dataset pour quâ€™il soit utilisÃ© par la pipeline.
- coder un premier exemple avec CPC, F1-Score et le dataset https://pubmed.ncbi.nlm.nih.gov/15845847/.
- continuer avec les autres algos.

---

# Ã‰tat actuel de l'implÃ©mentation

## Composants implÃ©mentÃ©s

### Pipeline principal (âœ… Fait)
- **Pipeline.py** : Orchestration principale avec la classe `StructureLearningPipeline`
- **Dataset.py** : Wrapper de donnÃ©es avec gestion des types (continu/discret)
- **Result.py** : Stockage des rÃ©sultats avec dictionnaire de mÃ©triques
- **Structure.py** : ReprÃ©sentation du CPDAG avec `gum.EssentialGraph`

### Algorithmes (ğŸ”„ En cours)
- **AlgorithmAdapter.py** : Classe abstraite de base pour tous les algorithmes
- **CPCAdapter.py** : Algorithme CPC continu depuis otagrum (âœ… implÃ©mentÃ©)
- Autres : TODO (CMIIC, CPC2, CMIIC2, NOTEARS, LiNGAM, discrÃ©tisation + MIIC/GHC)

### MÃ©triques (ğŸ”„ En cours)
- **MetricAdapter.py** : Classe abstraite de base pour toutes les mÃ©triques
- **SHDMetric.py** : Structural Hamming Distance (âœ… implÃ©mentÃ©)
- Autres : TODO (F1-Score, TPR)

### Autres modules
- **discretization/** : TODO (stratÃ©gies de conversion continuâ†’discret)
- **visualization/** : TODO (heatmaps et visualisation des rÃ©sultats)

### Tests & Exemples
- **tests/integration/test_cpc_shd.py** : Test d'intÃ©gration basique avec CPC + SHD
- **examples/basic_usage.py** : Exemple d'utilisation complet avec donnÃ©es synthÃ©tiques

## Structure actuelle du projet

```
cbnsl_benchmark/
â”œâ”€â”€ pipeline/              # Core pipeline components
â”‚   â”œâ”€â”€ Pipeline.py        # Main orchestration
â”‚   â”œâ”€â”€ Dataset.py         # Dataset wrapper
â”‚   â”œâ”€â”€ Result.py          # Result storage
â”‚   â””â”€â”€ Structure.py       # Structure representation (CPDAG)
â”‚
â”œâ”€â”€ algorithms/            # Algorithm adapters
â”‚   â”œâ”€â”€ AlgorithmAdapter.py    # Base adapter interface
â”‚   â”œâ”€â”€ CPCAdapter.py          # CPC/CPC2 continu (otagrum) (âœ…)
â”‚   â”œâ”€â”€ CMIICAdapter.py        # CMIIC/CMIIC2 continu (otagrum) (âœ…)
â”‚   â”œâ”€â”€ MIICAdapter.py         # MIIC discret + discrÃ©tisation (pyAgrum) (âœ…)
â”‚   â””â”€â”€ GHCBDeuAdapter.py      # GHC+BDeu discret + discrÃ©tisation (pyAgrum) (âœ…)
â”‚
â”œâ”€â”€ metrics/              # Evaluation metrics
â”‚   â”œâ”€â”€ MetricAdapter.py      # Base metric interface
â”‚   â””â”€â”€ SHDMetric.py         # Structural Hamming Distance (âœ…)
â”‚
â”œâ”€â”€ analysis/             # Benchmark analysis and visualization
â”‚   â””â”€â”€ BenchmarkAnalyzer.py  # Metrics vs golden, pairwise, heatmaps (âœ…)
â”‚
â”œâ”€â”€ tests/               # Tests
â”‚   â”œâ”€â”€ unit/            # Unit tests (TODO)
â”‚   â”œâ”€â”€ integration/     # Integration tests
â”‚   â”‚   â””â”€â”€ test_cpc_shd.py
â”‚   â””â”€â”€ fixtures/        # Test data (TODO)
â”‚
â”œâ”€â”€ examples/            # Usage examples
â”‚   â””â”€â”€ basic_usage.py
â”‚
â”œâ”€â”€ data/                # Datasets
â”‚   â””â”€â”€ synthetic/       # Synthetic datasets
â”‚
â”œâ”€â”€ results/             # Benchmark outputs (gitignored)
â”‚
â”œâ”€â”€ .context/            # Contexte IA (pas dans le package)
â”‚   â”œâ”€â”€ architecture.md  # Ce fichier
â”‚   â””â”€â”€ useful_links.md  # Liens vers code/docs externes
â”‚
â”œâ”€â”€ install.sh           # Script d'installation automatique
â”œâ”€â”€ pyproject.toml       # Configuration du package
â”œâ”€â”€ requirements.txt     # DÃ©pendances de base
â””â”€â”€ requirements-git.txt # DÃ©pendances Git
```

## DÃ©cisions architecturales (Ã©tat actuel)

### Organisation du projet

**tests/ (pluriel, pas test/)** : Suit la convention Python. SubdivisÃ© en unit/, integration/ et fixtures/ pour une meilleure organisation.

**SÃ©paration examples/ et tests/** : Distinction claire entre exemples d'utilisation et tests. Les exemples montrent comment utiliser la lib, les tests vÃ©rifient la correction.

**data/ pour datasets, results/ pour outputs** : Garde le code propre. Les deux sont gitignorÃ©s (sauf structure) pour Ã©viter de versionner de gros fichiers.

**Dataset dans pipeline/ (pas dans data/)** : `Dataset` est une abstraction avec logique (wrapper + mÃ©tadonnÃ©es), pas des donnÃ©es brutes. Appartient aux autres abstractions core comme `Result` et `Structure`.

**.context/ pour contexte IA** : Contient documentation architecture et liens externes. Pas partie du package, seulement pour dev/assistance IA.

### SystÃ¨me de types & ReprÃ©sentations

**Structure.cpdag typÃ© comme `gum.EssentialGraph`** :
- PyAgrum utilise `EssentialGraph` comme reprÃ©sentation interne d'un CPDAG
- On garde le nom conceptuel "cpdag" (Ã§a reprÃ©sente un CPDAG) mais avec des type hints honnÃªtes
- La mÃ©thode `.pdag()` convertit vers reprÃ©sentation PDAG pour l'affichage

**Pourquoi pas MixedGraph ?** : Initialement typÃ© comme `MixedGraph`, mais c'Ã©tait incorrect. `EssentialGraph` est plus spÃ©cifique et prÃ©cis.

### Conversion CPDAG â†’ BayesNet pour le calcul de SHD

**ProblÃ¨me** : `GraphicalBNComparator` de pyAgrum attend des `BayesNet` en entrÃ©e, mais un `BayesNet` hÃ©rite de `DAG` qui ne supporte que des arcs dirigÃ©s (`addArc`). Or nos structures apprises sont des CPDAGs (MixedGraph) qui contiennent des arÃªtes non-dirigÃ©es (edges). Une conversion naÃ¯ve CPDAG â†’ BayesNet perd ces edges, ce qui fausse complÃ¨tement le calcul de SHD (toutes les distances deviennent 0).

**Solution** : Avant de construire le BayesNet, on complÃ¨te le CPDAG en DAG complet via `gum.MeekRules().propagateToDAG(cpdag)`. Les Meek rules orientent les edges restantes de maniÃ¨re cohÃ©rente avec la classe d'Ã©quivalence de Markov. Ensuite, `GraphicalBNComparator.hamming()` retrouve le CPDAG original via `EssentialGraph` avant de comparer.

**DÃ©tail du calcul SHD par `hamming()`** : Pour chaque paire de variables, la mÃ©thode compare ce qui existe dans les deux CPDAGs et incrÃ©mente les compteurs :

| Ref | Test | pure hamming | structural hamming |
|---|---|---|---|
| `Aâ†’B` | `Aâ†’B` | 0 | 0 |
| `Aâ†’B` | `Bâ†’A` ou `Aâ€”B` | 0 | +1 (mauvaise orientation) |
| `Aâ†’B` | rien | +1 | +1 (arc manquant) |
| `Aâ€”B` | `Aâ†’B` ou `Bâ†’A` | 0 | +1 (orientÃ© alors que non-dirigÃ©) |
| `Aâ€”B` | `Aâ€”B` | 0 | 0 |
| `Aâ€”B` | rien | +1 | +1 (edge manquant) |
| rien | quelque chose | +1 | +1 (en trop) |

Notre code utilise `structural hamming` qui compte : arcs manquants + arcs en trop + arcs mal orientÃ©s.

**Note** : on pourrait aussi dÃ©cider de compter 2 erreurs pour les orientations dans le mauvais sens ou les arcs orientÃ©s lÃ  oÃ¹ il ne devrait rien y avoir.

### Pourquoi F1-Score et TPR sont implÃ©mentÃ©s Ã  la main

Pour le SHD, on utilise `GraphicalBNComparator.hamming()` de pyAgrum qui reconvertit internement les BayesNets en CPDAGs avant de comparer. Pour le F1-Score et le TPR (recall), deux options existaient dans pyAgrum :

1. **`GraphicalBNComparator.scores()`** (`bn_vs_bn.py`) : compare les **DAGs** directement (`existsArc` sur le BayesNet). ProblÃ¨me : la complÃ©tion du CPDAG en DAG via MeekRules est arbitraire au sein de la classe d'Ã©quivalence de Markov. Contrairement Ã  `hamming()` qui reconvertit en CPDAG en interne, `scores()` ne le fait pas. Le F1/recall dÃ©pendrait donc du DAG choisi par MeekRules, pas du CPDAG rÃ©el.

2. **`gum.StructuralComparator`** (binding C++) : compare correctement des PDAG en prenant en compte arcs et edges. Mais le binding SWIG dispatche `MixedGraph` vers la surcharge `UndiGraph` (hÃ©ritage multiple : `MixedGraph(UndiGraph, DiGraph)`), ce qui fait qu'il ne voit que les edges et ignore les arcs. VÃ©rifiÃ© expÃ©rimentalement : passer deux `MixedGraph` avec uniquement des arcs donne `precision=nan, recall=nan`. Seuls les objets `gum.PDAG` fonctionnent correctement, mais on ne peut pas utiliser PDAG car un CPDAG peut contenir des cycles non-dirigÃ©s (ex : A â€” B â€” C â€” A, triangle sans v-structure) que PDAG refuserait.

**Solution retenue** : implÃ©menter F1 et TPR directement sur `MixedGraph`, en reprenant la stratÃ©gie de comptage de `StructuralComparator` (la logique C++ est correcte, c'est le binding SWIG qui pose problÃ¨me). Pour chaque paire de nÅ“uds non ordonnÃ©e, on classifie la relation en 10 catÃ©gories :

| ref \ test | `â†’` (arc) | `â€”` (edge) | `X` (rien) |
|---|---|---|---|
| **`â†’`** | `true_arc` (TP) / `misoriented_arc` (FP) | `wrong_edge_arc` (FP) | `wrong_none_arc` (FN) |
| **`â€”`** | `wrong_arc_edge` (FP) | `true_edge` (TP) | `wrong_none_edge` (FN) |
| **`X`** | `wrong_arc_none` (FP) | `wrong_edge_none` (FP) | `true_none` (â€”) |

Voir https://gitlab.com/agrumery/aGrUM/-/blob/master/src/agrum/BN/algorithms/structuralComparator.h.

**Choix de la stratÃ©gie de comptage** : la distinction clÃ© concerne les liens mal orientÃ©s ou de mauvais type (arc vs edge). `StructuralComparator` les compte comme FP uniquement (le lien existe dans test mais est incorrect), pas comme FN (le lien de ref n'est pas "absent" dans test, il est juste mal reprÃ©sentÃ©). L'alternative (compter aussi comme FN) double-pÃ©naliserait ces erreurs. On considÃ¨re qu'un arc mal orientÃ© ou un arc au lieu d'une edge est moins grave qu'un lien complÃ¨tement absent, d'oÃ¹ le choix de ne compter qu'un FP.

Puis : recall (= TPR) = TP / (TP + FN), precision = TP / (TP + FP), F1 = 2Â·precisionÂ·recall/(precision+recall).

### DiscrÃ©tisation
Pour les approches sâ€™appliquant Ã  des donnÃ©es discrÃ¨tes, les performances dÃ©pendent fortement de la stratÃ©gie de discrÃ©tisation utilisÃ©e en amont deux mÃ©thodes sont explorÃ©es et une grille de bin de 1 Ã  10 sont testÃ©es grÃ¢ce Ã  ces mÃ©thode de discretisation :
- **DiscrÃ©tisation par quantiles** : dÃ©coupe lâ€™Ã©chelle des variables continues en classes de mÃªme effectif, garantissant une distribution uniforme des observations.
- **DiscrÃ©tisation Hartemink** : utilisÃ©e dans lâ€™Ã©tude de Sachs, cette mÃ©thode commence par une discrÃ©tisation initiale (paramÃ©trable dans notre pipeline), puis agrÃ¨ge les intervalles de maniÃ¨re Ã  maximiser la conservation de lâ€™information mutuelle conditionnelle entre les variables, prÃ©servant ainsi au mieux leurs dÃ©pendances.

Pour la discrÃ©tisation par quantiles on utilise la classe DiscreteTypeProcessor de agrum.

### Design Patterns

**Pattern Adapter pour Algorithmes** : DÃ©couple les implÃ©mentations externes de notre pipeline. Chaque algo (CPC, NOTEARS, LiNGAM) a son adapter implÃ©mentant l'interface `AlgorithmAdapter`.

**Pattern Adapter pour MÃ©triques** : Similaire aux algos, permet d'ajouter nouvelles mÃ©triques sans modifier la pipeline.

**Injection de DÃ©pendances** : Pipeline ne crÃ©e pas les algos ou mÃ©triques, ils sont injectÃ©s via `add_algorithm()`. Augmente flexibilitÃ© et testabilitÃ©.

### DiscrÃ©tisation intÃ©grÃ©e aux adapters

Les algorithmes discrets (MIIC, GHC+BDeu) gÃ¨rent la discrÃ©tisation en interne via `DiscreteTypeProcessor` de pyAgrum. Les paramÃ¨tres (n_bins, mÃ©thode) font partie de la configuration de l'adapter. Il n'y a pas de `DataType` ni de mÃ©canisme de conversion automatique dans la Pipeline : tous les adapters acceptent des donnÃ©es continues.

### Installation & DÃ©pendances

**Environnement Python** : On utilise un venv avec `--system-site-packages` pour avoir accÃ¨s aux packages C++ compilÃ©s (pyAgrum, openturns, otagrum) tout en isolant les packages pip (lingam, notears).

**Comment les packages sont installÃ©s :**
- **pyAgrum, openturns** : installÃ©s via pacman (paquets Arch) â†’ `/usr/lib/python3.x/site-packages`
- **otagrum** : compilÃ© depuis le fork C++ et installÃ© via `cmake --install` avec `CMAKE_INSTALL_PREFIX=$HOME/.local` â†’ `~/.local/lib/python3.x/site-packages`
- **lingam, notears** : installÃ©s via `pip install` dans le venv â†’ `venv/lib/python3.x/site-packages`

**Pourquoi `--system-site-packages` ?** Manjaro (Arch) applique PEP 668 qui interdit pip d'installer hors d'un venv. Un venv standard ne voit pas les packages systÃ¨me (pyAgrum, openturns) ni les packages utilisateur (otagrum dans `~/.local/`). Le flag `--system-site-packages` rend ces packages visibles dans le venv, tout en permettant `pip install` normal pour les packages Python purs (lingam, notears).

**Activation du venv :** `source venv/bin/activate` ou utiliser directement `venv/bin/python`.

**pyproject.toml pour config package** : Standard moderne Python (PEP 621). DÃ©finit dÃ©pendances et mÃ©tadonnÃ©es du package.

**requirements-git.txt sÃ©parÃ©** : Certaines dÃ©pendances (otagrum avec CPC2/CMIIC2, notears) viennent de dÃ©pÃ´ts Git, pas PyPI.

**Script install.sh automatisÃ©** : Installation interactive gÃ©rant conda vs build cmake pour otagrum, NO TEARS optionnel, etc.

## FonctionnalitÃ©s Ã  implÃ©menter
- [ ] Algorithmes restants : NOTEARS, LiNGAM, DiscrÃ©tisation Hartemink
- [ ] MÃ©triques restantes : F1-Score, TPR
- [ ] Grille de bins (1-10) pour les algorithmes avec discrÃ©tisation
- [ ] Export des rÃ©sultats (CSV, JSON)
- [ ] Mesure du temps d'exÃ©cution

## Conventions de code
- Code et commentaires en anglais
- Type hints systÃ©matiques
- Docstrings au format Google
- Pas d'emojis sauf demande explicite
